steelstore <- read.csv("C:/Users/onyeka/Desktop/CLA/Steel store analysis/steelstore.csv")
View(steelstore)
library("stats4", lib.loc="C:/Program Files/R/R-3.1.2/library")
library("stats", lib.loc="C:/Program Files/R/R-3.1.2/library")
library("graphics", lib.loc="C:/Program Files/R/R-3.1.2/library")
library("foreign", lib.loc="C:/Program Files/R/R-3.1.2/library")
library("rstudio", lib.loc="~/R/win-library/3.1")
library("psych", lib.loc="~/R/win-library/3.1")
library("psych", lib.loc="~/R/win-library/3.1")
library("rstudio", lib.loc="~/R/win-library/3.1")
load("C:\\Users\\onyeka\\Desktop\\CLA\\Loyalty & NPS linkage analysis\\R analysis\\analysis")
local({fn<-choose.files(filters=Filters[c('R','txt','All'),],index=4)
file.show(fn,header=fn,title='')})
q()
load("C:\\Users\\ONYEKA\\Desktop\\CLA\\Loyalty & NPS linkage analysis\\NPS-Loyalty-Booking-FS-Questions-FY15.csv")
fy15= read.csv("C:\\Users\\ONYEKA\\Desktop\\CLA\\Loyalty & NPS linkage analysis\\NPS-Loyalty-Booking-FS-Questions-FY15.csv")
library(MASS)
Recommend.f=factor(fy15$Recommend)
levels(Recommend)
levels(Recommend.f)
levels(Expect.to.Increase.NetApp.Spend)
levels(fy15$Expect.to.Increase.NetApp.Spend)
Expect.to.Increase.NetApp.Spend.f=factor(fy15$Expect.to.Increase.NetApp.Spend, levels=c("Decrease Substantially","Decrease Somewhat","Stay about the Same","Increase Somewhat","Increase Substantially")
Expect.to.Increase.NetApp.Spend.f=factor(fy15$Expect.to.Increase.NetApp.Spend, levels=c("Decrease Substantially","Decrease Somewhat","Stay about the Same","Increase Somewhat","Increase Substantially"))
Expect.to.Increase.NetApp.Spend.f=factor(fy15$Expect.to.Increase.NetApp.Spend, levels=c("Decrease Substantially","Decrease Somewhat","Stay About the Same","Increase Somewhat","Increase Substantially"))
levels(Expect.to.Increase.NetApp.Spend.f)
r=polr(Expect.to.Increase.NetApp.Spend.f~Recommend.f, data=fy15, method=c("logistic"))
summary(r)
s=polr(Expect.to.Increase.NetApp.Spend.~Recommend.f, data=fy15, method=c("logistic"))
s=polr(Expect.to.Increase.NetApp.Spend.~Recommend, data=fy15, method=c("logistic"))
s=polr(Expect.to.Increase.NetApp.Spend.f~Recommend, data=fy15, method=c("logistic"))
summary(s)
olr in r
levels(fy15$Individual.NPS)
Individual.NPS.f=factor(fy15$Individual.NPS, c("Detractor","Neutral",Promoter"))
Individual.NPS.f=factor(fy15$Individual.NPS, c("Detractor","Neutral","Promoter"))
Individual.NPS.f=factor(fy15$Individual.NPS, c("Detractor","Neutral","Promoter"))
levels(Individual.NPS.f)
t=lm(fy15$FY15.WW.Booking~Individual.NPS.f)
summary(t)
t=lm(fy15$FY15.WW.Booking~Individual.NPS.f, method=c("logistic"))
t=glm(fy15$FY15.WW.Booking~Individual.NPS.f)
summary(t)
save.image("C:\\Users\\ONYEKA\\Documents\\R\\.RData")
q()
installed.packages(dev.tool)
install.packages(dev.tool)
install.packages(dev.tools)
find.package(devtools)
install.packages(devtools)
find.package("devtools"")
find.package("devtools")
find.package("devtools")
install.packages("devtools")
find.package("devtools")
library(devtools)
# installing/loading the package:
if(!require(installr)) {
install.packages("installr"); require(installr)} #load / install+load installr
# using the package:
updateR() # this will start the updating process of your R installation.  It will check for newer versions, and if one is available, will guide you through the decisions you'd need to make.
# installing/loading the package:
if(!require(installr)) {
install.packages("installr"); require(installr)} #load / install+load installr
# using the package:
updateR() # this will start the updating process of your R installation.  It will check for newer versions, and if one is available, will guide you through the decisions you'd need to make.
library(devtools)
find_rtools()
find.package("devtools")
install.packages("devtools")
install.packages("devtools")
find.package("devtools")
library(devtools)
find_rtools()
install.packages("KernSmooth")
load(KernSmooth)
load("KernSmooth")
library("KernSmooth")
swirl()
library("swirl")
swirl()
get(wd)
getwd()
ls()
x<-9
ls(0)
ls()
list.files()
dir()
?list.files
arg(list.files)
arg(list.files())
args(list.files)
old.dir <- getwd()
setwd("C:/Users/ONYEKA/Desktop/Mine/Training/Data science - johns hopkins/2-R programming")
old.dir <- getwd()
dir.create("testdir")
setwd(testdir)
setwd("testdir"")
setwd("testdir")
file.create("mytest.R")
ls()
getwd()
list.files()
file.exists()
file.exists("mytest.R")
file.info(mytest.R)
file.info("mytest.R"")
file.info("mytest.R")
file.rename("mytest2.R")
file.rename("mytest.R" to "mytest2.R")
file.rename("mytest.R" to "mytest2.R")
args(file.rename)
file.rename(from "mytest.R" to "mytest2.R")
file.rename("mytest.R", "mytest2.R")
file.copy("mytest2.R", "mytest3.R")
file.path("mytest3.R")
file.path("folder1","folder2")
?dir.create
dir.create("testdir2/testdir3", recursive=T)
getwd()
dir.create("testdir2", "testdir3", recursive=T)
dir.create(file.path('testdir2', 'testdir3'), recursive=T)
dir.create(file.path('testdir2', 'testdir3'), recursive=TRUE)
unlink("testdir2", recursive=TRUE)
setwd(old.dir)
unlink("testdir")
unlink("testdir", recursive=TRUE)
bye()
swirl()
swirl()
load(swirl)
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
library("rJava", lib.loc="~/R/win-library/3.3")
fileUrl4 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(url=fileUrl4, destfile="./idahohousing.csv", mode="w", method="auto")
dateDownloaded <- date()
print(dateDownloaded)
library(data.table)
DT <- fread(input="idahohousing.csv", sep=",")
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT[DT$SEX==1,]$pwgtp15))
system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
DT[,mean(pwgtp15),by=SEX]\
DT[,mean(pwgtp15),by=SEX]
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(DT[,mean(pwgtp15),by=SEX], digits.secs=6)
library("KernSmooth", lib.loc="C:/Program Files/R/R-3.3.1/library")
x<-1:4
y<-2:3
x+y
x <- c(4, "a", TRUE)?
x <- c(4, "a", TRUE)
class(x)
## makeCacheMatrix creates a special "matrix" object, that can cache its inverse.
##which is really a list containing a function to
## set the value of the matrix
#get the value of the matrix
#set the value of the matrix inverse
#get the value of the matrix inverse
makeCacheMatrix <- function(x = matrix()) {
inv_matrix <- NULL
set <- function(y) {
x <<- y
inv_matrix <<- NULL
}
get <- function() x
setinv <- function(solve) inv_matrix <<- solve
getinv <- function() inv_matrix
list(set = set, get = get,
setinv = setinv,
getinv = getinv)
}
## cacheSolve computes the inverse of the special 'matrix' returned by makeCacheMatrix above
## If the inverse has already been calculated (and the matrix has not changed)
#then cacheSolve will retrieve the inverse from the cache.
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
inv_matrix <- x$getinv()
if(!is.null(inv_matrix) & identical(x,y)) {
message("getting cached data")
return(inv_matrix)
}
data <- x$get()
inv_matrix <- solve(data, ...)
x$setinv(inv_matrx)
inv_matrix
}
makeCacheMatrix()
)
makeCacheMatrix()
makeCacheMatrix(2)
cacheSolve
cacheSolve()
cacheSolve(x)
cacheSolve(2)
x<-c(2,3)
x
makeCacheMatrix(x)
cacheSolve(x)
getwd()
library("swirl")
install_from_swirl("Exploratory Data Analysis")
ls()
getwd()
rm(list=ls())
ls()
swirl()
require(ggplot2, dplyr, plyr)
library("dplyr")
if(!file.exists('activity.csv')){
unzip('activity.zip')
}
activityDT <- read.csv('activity.csv')
setwd("~/GitHub/RepData_PeerAssessment1")
if(!file.exists('activity.csv')){
unzip('activity.zip')
}
activityDT <- read.csv('activity.csv')
if(!file.exists('activity.csv')){
unzip('activity.zip')
}
activityDT <- read.csv('activity.csv')
require(ggplot2, dplyr, plyr)
library("dplyr")
require(ggplot2, dplyr)
library("dplyr")
require(ggplot2, dplyr)
library("dplyr")
library("dplyr", lib.loc="~/R/win-library/3.3")
StepsPerDay <- tapply(activityDT$steps, activityDT$date, sum, na.rm=TRUE)
qplot(StepsPerDay, binwidth=1000, xlab="Total steps per day", ylab="Frequency")
require(ggplot2, dplyr)
library("dplyr", "ggplot2")
library("ggplot2", lib.loc="~/R/win-library/3.3")
qplot(StepsPerDay, binwidth=1000, xlab="Total steps per day", ylab="Frequency")
StepsPerDayMean <- mean(StepsPerDay)
StepsPerDayMedian <- median(StepsPerDay)
AvgStepPerInterval<- activityDT %>%
group_by(interval) %>%
summarise(AvgSteps = mean(steps, na.rm=TRUE))
ggplot(data=AvgStepPerInterval, aes(x=interval, y=AvgSteps)) +
geom_line() +
xlab("5-minute interval") +
ylab("average number of steps taken")
ggplot(data=AvgStepPerInterval, aes(x=interval, y=AvgSteps)) +
geom_line() +
xlab("5-minute interval") +
ylab("average number of steps taken")
MaxNumofSteps <- which.max(AvgStepPerInterval$AvgSteps)
timeMaxNumofSteps <-  gsub("([0-9]{1,2})([0-9]{2})", "\\1:\\2", AvgStepPerInterval[MaxNumofSteps,"interval"])
NumMissingValue <- sum(is.na(activityDT$steps))
DTFilled <- activityDT
UniqueInterval<-unique(DTFilled$interval)
for (i in 1:length(UniqueInterval)){
DTFilled[(DTFilled$interval == UniqueInterval[i]) & is.na(DTFilled$steps),][,"steps"] <- AvgStepPerInterval$AvgSteps[i]
}
StepsPerDayFilled <- tapply(DTFilled$steps, DTFilled$date, sum)
qplot(StepsPerDayFilled, binwidth=1000, xlab="Total steps per day", ylab="Frequency")
StepsPerDayFilledMean <- mean(StepsPerDayFilled)
StepsPerDayFilledMedian <- median(StepsPerDayFilled)
DTFilled$dateWeek <- ifelse(weekdays(as.POSIXlt(DTFilled$date)) %in% c("Saturday", "Sunday"), "weekend", "weekday")
DTFilled$dateWeek <- as.factor(DTFilled$dateWeek)
AvgStepPerIntervalFilled <- DTFilled %>%
group_by(interval, dateWeek) %>%
summarise(AvgSteps = mean(steps, na.rm=TRUE))
view(AvgStepPerIntervalFilled)
View(AvgStepPerIntervalFilled)
ggplot(AvgStepPerIntervalFilled, aes(interval, AvgSteps)) +
geom_line() +
facet_grid(dateWeek ~ .) +
xlab("5-minute interval") +
ylab("average number of steps")
# Chunk 1
require(ggplot2, dplyr)
library("dplyr", "ggplot2")
# Chunk 2
if(!file.exists('activity.csv')){
unzip('activity.zip')
}
activityDT <- read.csv('activity.csv')
# Chunk 3
StepsPerDay <- tapply(activityDT$steps, activityDT$date, sum, na.rm=TRUE)
# Chunk 4
qplot(StepsPerDay, binwidth=1000, xlab="Total steps per day", ylab="Frequency")
# Chunk 5
StepsPerDayMean <- mean(StepsPerDay)
StepsPerDayMedian <- median(StepsPerDay)
# Chunk 6
AvgStepPerInterval<- activityDT %>%
group_by(interval) %>%
summarise(AvgSteps = mean(steps, na.rm=TRUE))
# Chunk 7
ggplot(data=AvgStepPerInterval, aes(x=interval, y=AvgSteps)) +
geom_line() +
xlab("5-minute interval") +
ylab("average number of steps taken")
# Chunk 8
MaxNumofSteps <- which.max(AvgStepPerInterval$AvgSteps)
timeMaxNumofSteps <-  gsub("([0-9]{1,2})([0-9]{2})", "\\1:\\2", AvgStepPerInterval[MaxNumofSteps,"interval"])
# Chunk 9
NumMissingValue <- sum(is.na(activityDT$steps))
# Chunk 10
DTFilled <- activityDT
UniqueInterval<-unique(DTFilled$interval)
for (i in 1:length(UniqueInterval)){
DTFilled[(DTFilled$interval == UniqueInterval[i]) & is.na(DTFilled$steps),][,"steps"] <- AvgStepPerInterval$AvgSteps[i]
}
# Chunk 1
require(ggplot2, dplyr)
library("dplyr", "ggplot2")
# Chunk 2
if(!file.exists('activity.csv')){
unzip('activity.zip')
}
activityDT <- read.csv('activity.csv')
# Chunk 3
StepsPerDay <- tapply(activityDT$steps, activityDT$date, sum, na.rm=TRUE)
# Chunk 4
qplot(StepsPerDay, binwidth=1000, xlab="Total steps per day", ylab="Frequency")
# Chunk 5
StepsPerDayMean <- mean(StepsPerDay)
StepsPerDayMedian <- median(StepsPerDay)
# Chunk 6
AvgStepPerInterval<- activityDT %>%
group_by(interval) %>%
summarise(AvgSteps = mean(steps, na.rm=TRUE))
# Chunk 7
ggplot(data=AvgStepPerInterval, aes(x=interval, y=AvgSteps)) +
geom_line() +
xlab("5-minute interval") +
ylab("average number of steps taken")
# Chunk 8
MaxNumofSteps <- which.max(AvgStepPerInterval$AvgSteps)
timeMaxNumofSteps <-  gsub("([0-9]{1,2})([0-9]{2})", "\\1:\\2", AvgStepPerInterval[MaxNumofSteps,"interval"])
# Chunk 9
NumMissingValue <- sum(is.na(activityDT$steps))
# Chunk 10
DTFilled <- activityDT
UniqueInterval<-unique(DTFilled$interval)
for (i in 1:length(UniqueInterval)){
DTFilled[(DTFilled$interval == UniqueInterval[i]) & is.na(DTFilled$steps),][,"steps"] <- AvgStepPerInterval$AvgSteps[i]
}
# Chunk 11
StepsPerDayFilled <- tapply(DTFilled$steps, DTFilled$date, sum)
qplot(StepsPerDayFilled, binwidth=1000, xlab="Total steps per day", ylab="Frequency")
StepsPerDayFilledMean <- mean(StepsPerDayFilled)
StepsPerDayFilledMedian <- median(StepsPerDayFilled)
# Chunk 1
require(ggplot2, dplyr)
library("dplyr", "ggplot2")
# Chunk 2
if(!file.exists('activity.csv')){
unzip('activity.zip')
}
activityDT <- read.csv('activity.csv')
# Chunk 3
StepsPerDay <- tapply(activityDT$steps, activityDT$date, sum, na.rm=TRUE)
# Chunk 4
qplot(StepsPerDay, binwidth=1000, xlab="Total steps per day", ylab="Frequency")
# Chunk 5
StepsPerDayMean <- mean(StepsPerDay)
StepsPerDayMedian <- median(StepsPerDay)
# Chunk 6
AvgStepPerInterval<- activityDT %>%
group_by(interval) %>%
summarise(AvgSteps = mean(steps, na.rm=TRUE))
# Chunk 7
ggplot(data=AvgStepPerInterval, aes(x=interval, y=AvgSteps)) +
geom_line() +
xlab("5-minute interval") +
ylab("average number of steps taken")
# Chunk 8
MaxNumofSteps <- which.max(AvgStepPerInterval$AvgSteps)
timeMaxNumofSteps <-  gsub("([0-9]{1,2})([0-9]{2})", "\\1:\\2", AvgStepPerInterval[MaxNumofSteps,"interval"])
# Chunk 9
NumMissingValue <- sum(is.na(activityDT$steps))
# Chunk 10
DTFilled <- activityDT
UniqueInterval<-unique(DTFilled$interval)
for (i in 1:length(UniqueInterval)){
DTFilled[(DTFilled$interval == UniqueInterval[i]) & is.na(DTFilled$steps),][,"steps"] <- AvgStepPerInterval$AvgSteps[i]
}
# Chunk 11
StepsPerDayFilled <- tapply(DTFilled$steps, DTFilled$date, sum)
qplot(StepsPerDayFilled, binwidth=1000, xlab="Total steps per day", ylab="Frequency")
StepsPerDayFilledMean <- mean(StepsPerDayFilled)
StepsPerDayFilledMedian <- median(StepsPerDayFilled)
